\documentclass[../summary.tex]{subfiles}

\begin{document}
	
	\section{Introduction}
	We beginnen met een quote van Marshall McLuhan uit 1969. De quote vertelt ons dat de evolutie van technologie niet gestopt kan worden, en dat protest het process niet zal stoppen. We zien een gelijkaardige statement, specifiek over AI, van Stuart Russell in 2021. Hij beweert dat superhuman intelligence er gegarandeerd aankomt, en dat het success er van tot het einde van het menselijk ras kan leiden.  \\
	
	We focusen hier dus op de ontwikkeling van `general AI', komende van de `small AI' die we tegenwoordig utiliseren. Deze ontwikkeling is onvermijdelijk, en kunnen groei dus enkel proberen controleren om catastrophale gevolgen te voorkomen. \\
	
	Deze les gaan we een diepere kijk nemen op de `Determination Thesis' (Thorstein Veblen 1900). Determinisme slaagt op het feit dat iets onvoorkombaar, noodzakelijk of casuaal is. Deze thesis heeft verschillende invullingen van onvermijdelijke effecten zoals we verder in deze les zullen zien.  \\
	
	\subsection{Voorbeeld}
	Een eerste voorbeeld invulling is dat technologie altijd sociale effecten zal hebben:
	\begin{description}
		\item[pro: ] Auto's, telefoons, drugs, social media, etc. zijn allemaal ontwikkelingen die drastische sociale veranderingen hebben meegebracht voor de maatschappij.
		\item[con: ] De sociale effecten voorkomend uit technologie kunnen variëren. Lode spreekt hier over de mensheid als een `open systeem', in wijze dat het onvoorspelbaar is tegenover een `gesloten systeem' dat altijd hetzelfde resultaat zou bieden.
		\item[con: ]  De mens heeft in het verleden al veel voorspellingen gedaan, die compleet fout bleken te zijn. vb: Wright Brothers die dachten dat commercieële luchtvaart nog lang ging duren.
	\end{description}
	
	\subsection{Relevantie}
	Zoals eerder vermeld zijn er verschillende invullingen. Aangezien we industriële ingenieursstudenten zijn, gaan we deze les eerder focusen op technologisch determinisme. In dit techologisch determinisme zijn er vier types: Heidegger, social effects, creation of technology en evolution of technology. Bij de laatste twee is er een belangrijke morele en politieke relevantie.
	
	\subsubsection{Morele Relevantie}
	Als de ontwikkeling van een technologie gegarandeerd is, is diegene dat het uiteindelijk ontworpen heeft dan verantwoordelijk als de technologie wordt misbruikt? Men kan spreken van een zekere `responsibility gap'.
	
	Om dit idee van verandwoordelijkheid verder te verwerken, kijken we naar een gedachte experiment van Harry Frankfurt. Lode zegt het volgende: ``stel dat ik mijn vrouw wil vermoorden én dat ik een chip in mijzelf steek, mocht ik last-minute twijfels krijgen." In deze situatie zien we meteen dat de dood van zijn vrouw onvoorkombaar is, maar er zijn twee situaties:
	\begin{itemize}
		\item Lode krijgt geen twijfels en dood zijn vrouw op eigen houtje. In dit geval is het duidelijk dat Lode verantwoordelijk is.
		\item Lode krijgt last-minute twijfels en beslist zijn vrouw niet te vermoorden, waardoor de chip overneemt en de vrouw toch doodt. Lode kan dan niet meer verandwoordelijk genomen worden voor de dood.
	\end{itemize}
	Hieruit leren we dat, ondanks dat de gevolgen van iets vast liggen, er nog steeds een verschil kan zijn in verandwoordelijkheid. Een `responsibility gap' is in dit geval dus niet van toepassing. Met de focus op technologisch determinisme zal er dus iemand verandwoordelijk kunnen zijn, ondanks dat de creatie van een bepaalde technologie al vast ligt.
	
	\subsubsection{Politieke Relevantie}
	 De kwestie van verandwoordelijkheid kan meteen doorgetrokken worden naar een politiek vlak. We kunnen kijken naar het voorbeeld van Killer Robots.
	 % TODO kijk dees deel opnieuw in de les
	
	\section{First Determinism: Heidegger}
	
	
	\section{Second Determinism: Social Effects}
	
	\section{Third Determinism: Creation}
	
	\section{Fourth Determinism: Evolution}
	Over dit hoofdstuk worden geen vragen gesteld op het examen.
		
\end{document}